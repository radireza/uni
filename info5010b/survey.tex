\documentclass{article}

\usepackage{graphicx}
\usepackage{amssymb,amsmath}

\author{Nic Hollingum - 308193415}
\title{Security and Game Theory}

%\addtolength{\oddsidemargin}{-.875in}
%\addtolength{\evensidemargin}{-.875in}
%\addtolength{\textwidth}{1.75in}
%\addtolength{\topmargin}{-0.5in}
%\addtolength{\textheight}{1.5in}

\begin{document}
\maketitle

This report surveys the historic and current developments in the application of game theory to questions concerning security.
We do not limit the scope of the term {\em security}, and this applies to areas from real-world physical security to the development of secure policies for network management.
By necessity we limit those security applications to ones where a game-theoretic modelling of the problem or a game-theoretic understanding of the solution is applicable.

\section{Problem Formulations}

\subsection{Stochastic Games}
\label{secStoch}

Stochastic games are games centered around state-transition.
In general terms, both players have a predefined network of states with possible state-transitions marked as edges.
The players each have a utility function that determines how much it is worth for them to keep the game in a given state for some duration, and cost functions which determine how much utility a player looses trying to force a state transition.
State transitions typically occur probabilistically, where the probability of a state transition depends on the strategies of the players in the current state, and the desired transitions which those players make.

Formal definitions of these stochastic games can be found in \cite{network}.
We refer to the game with the tuple $(S, A^1, A^2, Q, R^1, R^2, \beta)$, where:
\begin{itemize}
	\item $S$: The set of possible states: ${s_1, ..., s_n}$
	\item $A^1$: The action set for player 1.
			Action sets list the possible moves for this player at each state, and the actions a player can take at a given state $A^1_{s_i} \subseteq A^1$.
			The union of all possible moves over all states is the action set.			
	\item $A^2$: As above for player 2.
	\item $Q$: The state transition function, which assigns probabilities of state transitions occuring given the actions of both players, the current state and the target state.
				Hence $Q: S \times A^1 \times A^2 \times S \rightarrow [0, 1]$.
	\item $R^1$: The reward function, which determines the utility of player 1 making a state transition given the current state and the action of player 2.
				Hence $R^1: S \times A^1 \times A^2 \rightarrow \mathbb{R}$
	\item $R^2$: As above for player 2.
	\item $\beta$: A discount factor for discounting future rewards.
			This quantity is used to more accurately model security problems, which occur infinitely.
			This would make it always preferable to ruthlessly seek the most profitable state no matter how unlikely that is to occur.
			In reality security adversaries tend to greedily seek the easiest profitable state, in otherwords they discount future gain for present reward.
			$\beta$ is in the range $]0, 1]$ for stackelberg games.
\end{itemize}

These models are applicable to certain kinds of security situations, particularly attack patterns on web servers.
\cite{network} adapts these kinds of general games to the game between an administrator and an attacker.
This paper uses reasonable probability estimates based on ``intuition and experience'', to determine the likelyhood of state transitions, as well as hard numbers on the profitability of attacks to determine reward functions.
Using these estimates the paper discovers the most optimal attack patterns, and therefore the most effective maves for the defender (administrator, player 2 in the paper).
More generally this method is used to determine the optimal assignment of security resources.

\subsection{Stackelberg Games}

Stackelberg games are two player games with a so-called {\em leader and follower} structure.
These kinds of games are more generally applicable, in the sense that any formal two player game can be a stacelberg game by adding the constraint that one player plays first and the other follows that player.
Stackelberg-type games are important in the security context as they more accurately model the kinds of games seen here.
In reality, attackers have ample time to observe the strategy played by the security agents, and it is a reasoable abstraction to assume that they follow the leader in that sense.

As an example of how stackelberg games affect normal games we look at a stackelberg formulation of the hawk and dove game.
Normally, the nash equilibria are (hawk, dove) and (dove, hawk), where both players play at the same time.
A stackelberg formulation requires one player to play first, in effect that player is able to choose which of the two equilibria will occur, so it is beneficial to always choose hawk, thus forcing the rational follower to play dove.
Similarly in the battle of the sexes game, when one player chooses first this communicates to the other and allows them to coordinate on their chosen destination.

However, stackelberg games do not necessarily favour the leader.
In the case of games with dominating strategies, such as the prisoners dilemma, knowing in advance by observing the other players move is no better than knowing in advance by reasoning that they will play the dominating strategy (provided they are rational).

In the case of security games, the stackelberg formulation typically favours the follower instead of the leader.
\cite{stackelberg} presents the intuitive understanding for why this is the case.
Realistically the job of security agents is to proactively prevent attacks from occuring, and react to attacks when they do occur.
The notion of leading the game means they play a strategy which minimises the chance of an attack occuring or forces only certain kinds of attacks to be viable, however they must then wait for that attack.
The attacker on the other hand can simply choose the most effective attack available to them and the optimal time to perform it, which is a considerable advantage.
It is usually not possible for security agents to guard against all attacks, due to the large number of possible attacks that can occur at any one time.


\subsection{Roaming Guards}

Continuing in the theme of developing models for security games we have those simulating the patrolling of guards.
These games are again concerned with optimally allocating resources (guards) to maximise utility (defence).
Specifically, these games provide abstractions for physical locations and are therefore used to determine optimal patrolling routes.

Games of this kind have a generalisation which is intuitively related to the problem.
\begin{itemize}
	\item this is a stackelberg game of two players, called the guard and the robber.
	\item There are $n$ houses, which the guard must defend, and the robber must rob.
	\item The robber has some utility for robbing each house, and a duration of the robbery.
	\item The guard moves between houses, paying some time to move between two houses, he spends 0 time at each house.
	\item If the robber is robbing a house when the guard moves there, the guard wins the game outright.
	\item We must formulate a patrol route for the guard so as to minimise the expected utility of the robber, and preferably make it 0.
	\item Both the guard and the robber may use mixed strategies.
\end{itemize}

We can view this generalisation graphically, in which case we see that there is a complete graph $k_n$.
We allow the guard to move between any two houses, however we may refine this problem to only allow the guard to move between certain houses.
This can be done without loss of generality by simply increasing the travel-time between houses to a large number.
Other variations call for multiple guards and multiple robbers.
One example of these variations is the ARMOR security system in Los Angeles International Airport, which will be discussed in Section \ref{secARMOR}.
The description of this variation can be found in \cite{random}.

Of particular interest here is the use of mixed strategies, which will be discussed further in Section \ref{secRandom}.
Strategy randomisation in these games is of intuitive importance here.
The game is typically modeled to have large negative cost to the robber if he is caught.
When the guard's patrol policy is not random (fixed strategy), the robber is able to observe this and plan the robberies accordingly, thereby guaranteeing a successful robbery.
When the guard's patrol policy is a mixed strategy, the robber can only know the probability of the guard patrolling each house, but never exactly when this happens.
This has the effect of making ``no robbery'' a desirable option for a rational robber.

\subsection{Markovian Decision Processes}

These problems are of particular importance to practical uses of game-theory in security.
Markovian decision processes, or problems, are not game theoretic themselves, in the sense that they do not have two players.
Instead they provide a one-player perspective of the kinds of Stackelberg games described in Section \ref{secStoch}.
They can be seen to simplify the stochastic games above in the following way:
\begin{itemize}
	\item The $A^2$ and $R^2$ sets are removed.
	\item The $\beta$ property is removed.
		This simplification occurs because markovian decision processes are only concerned with immediate payoffs, so discounting future payoffs which the $\beta$ is used for is an irrelevant concept.
	\item all other parts of the tuple are the same.
\end{itemize}

The way these problems relate to game-theory in security is that they allow us to play the stochastic games above without having any information about the attacker.
As was mentioned in \cite{network}, the probabilities and payoffs for both the administrator and the attacker were estimated by people close to the project.
However, whilst this knowledge may be available to webmasters who are the subject of numerous attacks each day, physical security applications are attacked much less frequently, and so-called ``expert'' appraisal is a less useful tool for them.
The markovian decision processes allow security applications to model the security problem without prior-knowledge of the attacker, then gradually build up a model of the attacked during operation.
Paruchuri et al demonstrate the effectiveness of this notion in \cite{random}.
In this case study the processes model the actions of the security agents so as to minimise the ammount of information that attackers can gain about them.
The processes are used in place of a game theoretic (stackelberg) model until sufficient information about the possible attack patterns and vulnerabilities is determined.

\newpage

\section{Strategies}

\subsection{Coalitional Security}

The development of optimal strategies for security problems cannot simply be abstracted by game solutions alone.
In practical applications several challenges above simply playing the security game must first be dealt with.
The first challenge recognised in the literature is the need for coordination and cooperation.
Research in this area seeks to formalise the strengths and weaknesses of employing cooperative strategies amongst security agents with similar goals.

The first consideration is for shared resources.
Organisations with multiple security divisions (say, guards for each site as well as admins for each server) by necessity overprovide security resources so as to ensure a minimal degree of protection.
Intuitively it is tempting to pool resources and meet this challenge.
Formulations for security games factor in advantages for coordinating amongst independent units to the utility functions of their agents moves.
This typically involves extending the normal stochastic game formulations to account for the multiple combined actions of all the security agents.

Similar to the shared benefits notion is the idea of shared vulnerabilities.
Security agents typically try to protect a place or system, and it is again intuitive that combining their efforts can provide better protection.
Whereas sharing resources prevents the excessive provision of security, when vulnerabilities are shared this maximisesthe security coverage of vulnerable parts of the system.
Considering the patrolling of guards, it may be beneficial to have agents from one division cover the vulnerabilities in another division, and vice versa, depending on the expertise of the agents in question and their locality to the vulnerability.

One issue with shared resources that was recognised early on and is integrated into game-theoretic models, is the notion of emergent vulnerabilities.
This idea captures the notion that combinations of certain security agents causes overheads or friction which detracts from the total effectiness of the coalition.
Consider the difficulties involved in having guards who use different communication protocols, different radio frequencies, different patrol sizes and timings and, realistically, different pay-grades, work together.
Firstly the overheads of facilitating this cooperation can be extreme, to the point that cooperation may be undesirable.
Also important is that the cooperation itself becomes an attack vector for the opposition, and so an entirely new vulnerability is created.
Again the general stochastic model must be modified to reflect these issues.

Much of the work on coalitional game-theory is summarised by Saad et al in \cite{coalition}.
This paper allows players in a multiagent stochastic game to form {\em coalitions} of agents which share utility and act jointly.
The emergent vulnerabilities are represented by a so-called {\em friction graph}, which changes the total effective utility in the problem depending on the coalitions form.
The goal of the game becomes to determine the {\em ideal cooperation protocol}, or which coalitions benefit the security agents most.

\subsection{Randomness}
\label{secRandom}

One reason why game theory is particularly applicable to security goals is the inbuilt notion of randomised strategies, called mixed strategies.
Whereas pure strategies for games are useful in most situations, namely situations where one move is clearly the best, in security applications this is not always the case.
Even having a single good strategy is itself a security risk, to the extent that it allows the opponent player to choose the best counter for this strategy.
Consider the stackelberg matching pennies game, wherein one player announces heads or tails and the follower then chooses heads or tails as per the rules of the game.
Clearly this game favours the follower, who can simply choose so as to win.
This situation is analogous to security problems, where it is inadvisable to allow your adversary to know your pure strategy.
A mixed strategy on the other hand describes a probability distribution over all strategies, preferably so that no strategy has probability 1.
As with the matching pennies game, it does your opponent to good if they know you will play heads with 50\% probability and tails with 50% probability.

In security applications randomness may refer to the following things:
\begin{itemize}
	\item Devising solutions which are mixed strategies, then selecting a play which performs those mixed strategies
	\item Randomisation in the objectives (goals) of the game
	\item Minor randomisation in the utility function of various aspects of the game
	\item Randomisation in the strategies available to the adversaries and security agents
	\item Randomisation in the structure of the game
	\item Dealing with unknowns (incomplete information) for all of the above
\end{itemize}

Paruchuri et al discuss implementation details and experimental results using randomised strategies in \cite{xrandom}.
That paper recognises the need for randomness to ``deteriorate an adversary's capability to predict and expoint [a security agent's] actions''.
The paper develops algorithms to determine optimal policies in both single-agent and multiagent settings.
Interestingly the paper does not use game-theoretic models to predict the actions of the adversary, but instead uses modified markovian decision processes to model the adversaries.
The procedure outlined fixes the maximum ammount of information which adversaries can gain by observing the agents (called entropy) and develops randomised solutions to the devision process.
The paper presents three algorithms which solve the problem, their running time is analysed and found to be fast (under 10 seconds) for realistic problem sizes.


\subsection{Communication}

Related to the need for coordination and cooperation amongst autonomous divisions of a security group, is the need for communication.
Communication is typically an important security goal, both in terms of coordinating agents as well as preventing information from falling into the hands of the adversaries.
Game theory can in this instance be used to formulate optimal strategies for communicating to minimise miscoordination and the information which adversaries can gain.

It is important again to consider the effects of policy randomisation on the security game here:
\begin{itemize}
	\item Randomised patrol routes must be kept secret from other agents (to minimise the ammount of information potential adversaries can gain), however to guard effectively, agents are allowed to know about current and historic movements of the other agents.
			To communicate this information can become problematic under realistic problem sizes, since the historic movement of one guard is pertinent information to all guards.
	\item Communicating new information gained as the result of random events (late aeroplanes, lost luggage, etc.) is necessary to continually evolve optimal strategy.
			Since the occurance of these events is not sensibly bounded, the communication requirements for the new information may similarly be unbounded.
\end{itemize}
\noindent In this way the use of randomised strategies makes understanding the communication requirements of certain security games more important.

Coordinating autonomous agents also necessarily entails communication.
Communication itself may be considered a shared or emergent vulnerability under models of coalitional security.
Saad et al do not deal with the necessity for communication in \cite{coalition}, as this is outside the scope of their work.
However the effectiveness or ineffectiveness of communication systems can necessitate certain joint actions that paper describes, which would not be necessary when communication is abstracted out.
For example, two sets of guards patrolling a structure must either both survey the entire structure, assume that the other's patroll went well, or communicate with each other when the patrol goes well.
Only in the later model can both sets of guards know the structure is secured without wasting resources.

Paruchuri et al deal with both the notion of coordinating agents and communicating in a randomised setting in \cite{random}.
This paper views communication as a finite resource in these security games and analyses whether it is possible to bound the communication requirements for randomised agents.
This paper builds on the work for developing random strategies in \cite{xrandom}.
The important obserrvation is that not all communication is necessary in order to keep all agents up to date with the movements of the other agents.
Since the agents know each others' mixed strategy, they can determine (probabilistically) the possible future routes of the other agents.
Updating all agents with the current state of each agent at fixed intervals allows them to refine this probabilistic estimate, and work out the historic movement of the other agents.
The paper presumes that some communication is allowed and that the adversaries cannot eavesdrop on the communication channel, hence the fixed update intervals prevent the adversary from using traffic analysis to determine some useful information about the guards strategies.


\subsection{Policy vs Optimality}

One important consideration in security applications is the modified understanding of ``optimality'' in thsi context.
Traditional gams and game formulations of other problems are able to seek optimality presuming the rationality of the opponent.
However security applications cannot in general assume the rationality of their adversaries.
This is not merely best practice by security firms, but is actually necessitated by the variations amongst possible threats.

Stochastic games are the main cause of this modification.
In simpler games the actions of the opponent can be rationally predicted, which determines the best strategy we can play.
However in stackelberg games the difference between an optimal and a suboptimal opponent may cause a very different traversal of the state network.
Indeed the actions of a rational opponent in a security context may always be ``give up'', yet still suboptimal adversaries are able to achieve positive utility by not following this strategy, even if the expected utility of these adversaries may be zero or less.

Since the actions chosen by the adversaries are also used to determine utility and future state in stochastic games, it is also important to predict suboptimality in order to maximise the utility of the security agents themselves.
In a real-world application this equates to security agents playing slightly suboptimally themselves so as to do things like, monitor unimportant targets more or less than their utility would necessitate.
Again this is intuitively related to the way stackelberg games work, and in effect handicaps the security agents so as to provide more complete defence.

The understanding of adversarial optimality is dealt with in varying ways in the literature:
\begin{itemize}
	\item Lye and Wing ignore this problem in \cite{network} and presume that the opposition (attacker) plays optimally, as does the administrator.
			This paper does recognise that modelling the actions of the attacker is difficult in practice, though they do not discuss the notion of suboptimal attackers.
	\item Paruchuri et al deal explicitly with the problems caused by suboptimal attackers in \cite{random, xrandom, stackelberg}.
			They describe a probability distribution over possible attacker types, where an attacker type is a theoretically optimal attacker with randomly skewed utilities.
			Skewing the utilities and then having the attacker play optimally is effectively like having a suboptimal attacker who favours certain attack patterns.
			The probability distributions are encorporated into this work by modifying both the markovian decision processes and stackelberg formulations into the POMDP and Bayesian stackelberg game formulations.
			These formulations require explicit knowledge of possible attacker types and their utilities.
			The paper does not discuss the difficulties involved in guessing in what way the opposition may be suboptimal.
\end{itemize}

\section{Application}

\subsection{Networks and Mobile}

\subsection{ARMOR}
\label{secARMOR}

\newpage

\bibliographystyle{plain}
\bibliography{biblio}

\end{document}
