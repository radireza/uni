\documentclass{article}

\usepackage{graphicx}
\usepackage{amssymb,amsmath}
\usepackage{theorem}

\author{Nic Hollingum - 308193415}
\title{Complexity}

\begin{document}

\begin{definition}
Graph $G$
\begin{align}
	\nonumber G = & (V,E) \\
	\nonumber V = & \{v_1, v_2, ..., v_n\} \quad & (vertices)\\
	\nonumber E \subseteq & V^2 & (edges)
\end{align}

We shall deal exclusively with so-called ``undirected'' graphs, in which $\forall (u,v) \in E : (u,v) = (v,u)$.
\end{definition}

\begin{definition}
Path Predicate.

This predicate $\pi$ is true in the following cases:

\begin{align}
	\nonumber \forall (u,v) \in V^2 : \pi(u, v) \Leftrightarrow & \langle (u, v) \in E \\
	\nonumber & \vee \langle \exists w \in V : \pi(u, w) \wedge (w, v) \in E \rangle \\
	\nonumber & \vee u = v \rangle
\end{align}

For simplicity we shall use $\not\pi(u, v)$ when the predicate does not hold.

For clarity we may say $\pi_{(V,E)}$ to explicitly state that this predicate applies to the graph $G=(V,E)$.

\end{definition}

\begin{definition}
{\em Multi-Terminal Cut}

Given a graph $G=(V,E,w,T)$, a set $T=\{t_1, t_2, ... t_k\}$ of $k$ specified vertices or {\em terminals} : $T \subseteq V$ , and a positive weight $w(e)$ for each edge, find a minimum weight set of edges $E' \subseteq E$ such that the removal of $E'$ from $E$ disconnects each terminal from all others.
An instance of MTC is therefore defined fromally:

\begin{align}
	\nonumber MTC = & (V,E,w,T)\\
	\nonumber & E \subseteq V^2\\
	\nonumber & w : E \rightarrow \mathbb{Z}^+\\
	\nonumber & T \subseteq V
\end{align}

Solution Space: $2^E$

Solution Cost: $C : 2^E \rightarrow \mathbb{Z}^+$
\begin{align}
	\nonumber C(S) = \displaystyle\sum\limits_{(u,v) \in S} w(u,v)
\end{align}

Feasible Solution Space: $F \subseteq 2^E$
\begin{align}
	\nonumber \forall (s, t) \in T^2 \setminus \{(r, r) | r \in T\} : \not\pi(s, t)
\end{align}

Optimal Solution Space: $O \subseteq F$
\begin{align}
	\forall S_j \in F , \quad \forall S_i \in O \quad \nonumber C(S_i) \leq C(S_j)
\end{align}

\end{definition}

\begin{definition}
The {\em Residual Graph} ($G_r$) is the graph of MTC(V,E,w,T) with the edges in its solution $S \in 2^E$ removed:

$G_r = (V, E \setminus S)$
\end{definition}

\begin{definition}
{\em Robust Actor Allocation}

Given a graph $G=(V,E,w_c,w_i)$, a partitioning of $V$ into $k$ subsets and a set of processors $P$, where $w_c : E \rightarrow \mathbb{Z}^+$ and $w_i : V \times P \rightarrow \mathbb{Z}^+$, find a mapping $\alpha : V \rightarrow P$ such that:
$\displaystyle\sum\limits_{(u,v) \in E : \alpha(u) \neq \alpha(v)} w_c(u,v) + \displaystyle\sum\limits_{v \in V} w_i(v, \alpha(v))$ is minimised and no actors in the same partition are assigned to the same processor.

\begin{align}
	\nonumber RAAP = & (V,E,w_c, w_i, P, A)\\
	\nonumber & E \subseteq V^2\\
	\nonumber & w_c : E \rightarrow \mathbb{Z}^+\\
	\nonumber & w_i : V \times P \rightarrow \mathbb{Z}^+\\
	\nonumber & P = \{p_1, p_2, ...p_p\} \\
	\nonumber & A = \{A_1, A_2, ..., A_k : \displaystyle\bigcup\limits_{i=1}^k A_i = V \wedge \forall A_i \neq A_j \in A : A_i \cap A_j = \emptyset\}
\end{align}

Solution Space: $\alpha \in P^V \subseteq P(V \times P)$

Solution Cost: $C : P^V \rightarrow \mathbb{Z}^+$
\begin{align}
	\nonumber C(\alpha) = \displaystyle\sum\limits_{(u,v) \in E : \alpha(u) \neq \alpha(v)} w_c(u,v) + \displaystyle\sum\limits_{v \in V} w_i(v, \alpha(v))
\end{align}

Feasible Solution Space: $F \subseteq P^V$
\begin{align}
	\nonumber C(\alpha) & \neq \infty \quad \mbox{We use $\infty$ as a placeholder for a very large integer} \\
	\nonumber \forall A_i \in A : \forall u \neq v \in A_i : \alpha(u) & \neq  \alpha(v)
\end{align}

Optimal Solution Space: $O \subseteq F$
\begin{align}
	\nonumber 	\forall \alpha_i \in O : \forall \alpha_j \in F : C(\alpha_i) \leq C(\alpha_j)
\end{align}

\end{definition}

\begin{definition}
Mapping

For convenience we shall call the feasible and optimal solution spaces and cost for the RAAP side of the mapping $F'$, $O'$ and $C'$ respectively.

\begin{align}
	\nonumber I \in & MTC(V,E,w,T) &\\
	\nonumber I' \in & RAAP(V', E', w_c, w_i, P, A) &\\
	\nonumber & I \mapsto I' if: &\\
	\nonumber V' & = V\\
	\nonumber E' & = E\\
	\nonumber P & = T\\
	\nonumber w_c & = w\\
	\nonumber w_i(v,p) & = \mbox{$\left\{ 
		\begin{array}{l l}
			0 \quad & \mbox{if $v \not\in T$}\\
			0 & \mbox{if $v \in T$ and $p = v$}\\
			\infty & \mbox{otherwise}\\ \end{array} \right.$} \\
	\nonumber A & = \{\{v\} | v \in V\}
\end{align}

We have used ``$=$'' to keep future descriptions simple, we really mean:
\begin{align}
	\nonumber \langle \exists f : V \rightarrow V' \quad s.t. & \\
	\nonumber & \forall v \in V : f(v) \in V'\\
	\nonumber & \forall (u, v) \in E : (f(u), f(v)) \in E' \\
	\nonumber & \forall t \in T : f(t) \in P\\
	\nonumber & \forall (u, v) \in E : w_c(f(u), f(v)) = w(u, v) \rangle
\end{align}

The above mapping makes $A = \{\{v\} | v \in V\}$ which makes it impossible to violate feasibility this way.
When talking about mapped instances we may therefore ignore it.
\end{definition}

\begin{definition}
Reversal Function $\gamma$

\begin{align}
	\nonumber \gamma & : P^V \rightarrow P(E) \\
	\nonumber \alpha & \mapsto \{(u,v) \in E | \alpha(u) \neq \alpha(v)\}
\end{align}
\end{definition}

\begin{definition}
Inversion Function $\gamma'$

\begin{align}
	\nonumber \gamma' & : P(E) \rightarrow P^V \\
	\nonumber S & \mapsto \forall v \in V' \alpha(v) = \mbox{$\left\{ 
		\begin{array}{l l}
			t \quad & \mbox{if $\exists t \in T : \pi_{(V, E \setminus S)} (v, t)$}\\
			t_0 & \mbox{otherwise}\\ \end{array} \right.$} 
\end{align}

For arbitrarily chosen $t_0 \in T$
\end{definition}

\begin{lemma}
\label{EDGEASSIGN}
The 2 nodes at the endpoint of any edge in the residual graph were assigned to the same processor:

\begin{align}
	\nonumber \forall(u, v) \in E \setminus \gamma(\alpha) : \alpha(u) = \alpha(v)
\end{align}
\end{lemma}
\begin{proof}
Immediate by definition of $\gamma$.
Otherwise $(u, v) \in \gamma(\alpha)$.
\end{proof}

\begin{lemma}
\label{PATHASSIGN}
The 2 nodes for which the path predicate is true in the residual graph were assigned to the same processor:

\begin{align}
	\nonumber \forall (u, v) \in V^2 : \pi_{(V, E \setminus \gamma(\alpha))}(u,v) \Rightarrow \alpha(u) = \alpha(v)
\end{align}
\end{lemma}
\begin{proof}
Using \ref{EDGEASSIGN} and induction on the path predicate.

In the trivial cases:
\begin{align}
	\nonumber \forall v \in V : \pi(v, v) & \Rightarrow \alpha(v) = \alpha(v) \\
	\nonumber \forall (u, v) \in E \setminus \gamma(\alpha) : \pi(u, v) & \Rightarrow \alpha(u) = \alpha(v) \quad \mbox{From \ref{EDGEASSIGN}}
\end{align}

Otherwise:
\begin{align}
	\nonumber \forall (u, v) \in V^2 : \pi(u, v) \Rightarrow \exists w \in V : \pi(u, w) \wedge (w, v) \in E \setminus \gamma(\alpha)
\end{align}

Clearly by \ref{EDGEASSIGN} $\alpha(w) = \alpha(v)$ and the definition recurs backwards until it is satisfied by one of the trivial cases.

\end{proof}

\begin{lemma}
\label{FORCEASSIGN}
Any feasible assignment $\alpha$ maps all terminals to themselves:

\begin{align}
	\nonumber \forall \alpha \in F' : \forall t \in T : \alpha(t) = t
\end{align}
\end{lemma}
\begin{proof}
Immediate by the definition of the mapping.
Otherwise $C(\alpha) = \infty$ and $\alpha \not\in F'$.
\end{proof}

\begin{lemma}
\label{REVERSEFEASABLE}
The reverse solution for any feasible $\alpha$ is also a feasible $S$.

\begin{align}
	\nonumber \forall \alpha \in F' : \gamma(\alpha) \in F
\end{align}
\end{lemma}
\begin{proof}
In other words, we must show that $\forall s \neq t \in T : \not\pi_{(V, E \setminus \gamma(\alpha))}(s, t)$.

To prove this by contradiction let us presume $\exists \beta \in F' : \gamma(\beta) \not\in F$.
Therefore $\exists (s, t) \in T^2 \setminus {(r,r) | r \in T} : \pi_{(V, E \setminus \gamma(\alpha))}(s, t)$.

First from \ref{FORCEASSIGN}:
\begin{align}
	\nonumber \forall t \in T : \beta(t) = t & \Rightarrow \beta(s) = s \wedge \beta(t) = t \\
	\nonumber & \Rightarrow \beta(s) \neq \beta(t)
\end{align}

Second from \ref{PATHASSIGN}:
\begin{align}
	\nonumber \forall (u, v) \in V^2 : \pi_{(V, E \setminus \gamma(\alpha))}(u,v) & \Rightarrow \alpha(u) = \alpha(v) \\
	\nonumber \pi(s, t) & \Rightarrow \beta(s) = \beta(t)
\end{align}

But this is a contradiction.
\end{proof}

\begin{lemma}
\label{SINGLEPATH}
Any node with a path to a terminal in the residual graph has no path to any other terminal in that graph.

\begin{align}
	\nonumber \forall v \in V, t \in T : \pi_{G_r}(v,t) \Rightarrow \forall s \in T \setminus {t} : \not\pi(v,s)
\end{align}
\end{lemma}
\begin{proof}
Immediate by definition of the feasible space.
Otherwise $\pi_{G_r}(v,t) \wedge \pi_{G_r}(v,s) \Rightarrow \pi_{G_r}(t,s)$ which means the curset was not feasible.
\end{proof}

\begin{lemma}
\label{INVERSECOST}
\end{lemma}
\begin{proof}
\end{proof}

\begin{lemma}
\label{REVERSEOPTIMAL}
\end{lemma}
\begin{proof}
\end{proof}

\bibliographystyle{plain}
\bibliography{biblio}

\end{document}